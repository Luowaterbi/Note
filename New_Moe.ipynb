{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= tensor([[ 1.2533,  0.4426,  1.5564, -1.6071, -0.6329, -0.8361],\n",
      "        [ 0.5491, -0.5321,  0.4401, -1.5789,  3.9186, -1.5876]])\n",
      "gates= tensor([[0.4248, 0.0000, 0.5752, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0333, 0.0000, 0.0000, 0.0000, 0.9667, 0.0000]],\n",
      "       grad_fn=<ScatterBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "softmax = nn.Softmax(-1)\n",
    "w_gate = torch.randn(4, 6)\n",
    "input = torch.randn(2, 4)\n",
    "logits = torch.mm(input,w_gate)\n",
    "top_k_logits, top_k_indices = logits.topk(2, dim=-1)\n",
    "top_k_gates = softmax(top_k_logits)\n",
    "zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "gates = zeros.scatter(-1, top_k_indices, top_k_gates)\n",
    "print(\"logits=\", logits)\n",
    "print(\"gates=\", gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c7d55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_expert= tensor([[0, 0],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 4]])\n",
      "sorted_experts= tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [1, 2],\n",
      "        [1, 4]])\n",
      "index_sorted_experts= tensor([[0, 0],\n",
      "        [1, 2],\n",
      "        [2, 1],\n",
      "        [3, 3]])\n",
      "_expert_index= tensor([[0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [4]])\n",
      "batch_index= tensor([0, 1, 0, 1])\n",
      "part_size= [2, 0, 1, 0, 1, 0]\n",
      "gates_exp= tensor([[0.4248, 0.0000, 0.5752, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0333, 0.0000, 0.0000, 0.0000, 0.9667, 0.0000],\n",
      "        [0.4248, 0.0000, 0.5752, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0333, 0.0000, 0.0000, 0.0000, 0.9667, 0.0000]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "_nonzero_gates tensor([[0.4248],\n",
      "        [0.0333],\n",
      "        [0.5752],\n",
      "        [0.9667]], grad_fn=<GatherBackward0>)\n"
     ]
    }
   ],
   "source": [
    "all_expert = torch.nonzero(gates)\n",
    "print(\"all_expert=\", all_expert)\n",
    "sorted_experts, index_sorted_experts = all_expert.sort(0)\n",
    "print(\"sorted_experts=\", sorted_experts)\n",
    "print(\"index_sorted_experts=\", index_sorted_experts)\n",
    "_, _expert_index = sorted_experts.split(1, dim=1)\n",
    "print(\"_expert_index=\", _expert_index)\n",
    "batch_index = all_expert[index_sorted_experts[:, 1],0]\n",
    "print(\"batch_index=\", batch_index)\n",
    "part_sizes = (gates > 0).sum(0).tolist()\n",
    "print(\"part_size=\", part_sizes)\n",
    "gates_exp = gates[batch_index]\n",
    "print(\"gates_exp=\", gates_exp)\n",
    "_nonzero_gates = torch.gather(gates_exp, 1, _expert_index)\n",
    "print(\"_nonzero_gates\", _nonzero_gates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be3f39d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[[0]],\n",
      "\n",
      "        [[1]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[1]]])\n"
     ]
    }
   ],
   "source": [
    "experts_from, experts_used = all_expert.split(1,dim=1)\n",
    "print(experts_from)\n",
    "experts_used, experts_used_index = experts_used.sort(0)\n",
    "experts_from = experts_from[experts_used_index.flatten()]\n",
    "print(experts_from)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaad065",
   "metadata": {},
   "outputs": [],
   "source": [
    "experts_used = experts_index[-1]  # [num_used_experts]\n",
    "experts_from = torch.stack(experts_index[:-1])  # [len(gates.shape), num_used_experts]\n",
    "experts_used, index_sorted_experts = experts_used.sort(stable=True)  # [num of used experts]\n",
    "experts_from = list(experts_from[..., index_sorted_experts])  # [tensor(num_used_experts), tensor(num_used_experts)]\n",
    "experts_gate = experts_gate[index_sorted_experts]  # [nus]\n",
    "experts_count = list(gates.reshape(-1, self.num_experts).count_nonzero(0))\n",
    "  # [num_epxerts]\n",
    "experts_input = x[experts_from]  # [nus, input_size]\n",
    "experts_input = torch.split(experts_input, experts_count, 0)\n",
    "experts_output = [self.experts[i](experts_input[i]) for i in range(self.num_experts)]\n",
    "experts_output = torch.cat(experts_output)  # [nus, output_size]\n",
    "experts_output *= experts_gate.unsqueeze(-1)  # [nus, output_size]\n",
    "# zeros = torch.zeros(x.shape[0], x.shape[1], self.output_size).cpu()  # [batch_size, ..., output_size]\n",
    "# zeros[experts_from] += experts_output.cpu()\n",
    "zeros = torch.zeros(x.shape[0], x.shape[1], self.output_size)  # [batch_size, ..., output_size]\n",
    "zeros[experts_from] += experts_output\n",
    "zeros = zeros.to(self.device)\n",
    "zeros = self.dropout(self.sigmod(zeros)) + x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9911af85466b16b744651dadc98a11dbcb38d984787025c3d0b6c21600a0af15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
