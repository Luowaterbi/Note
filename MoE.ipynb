{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f62347",
   "metadata": {
    "code_folding": [
     60,
     147,
     161
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "from inspect import isfunction\n",
    "\n",
    "# constants\n",
    "\n",
    "MIN_EXPERT_CAPACITY = 4\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def default(val, default_val):\n",
    "    default_val = default_val() if isfunction(default_val) else default_val\n",
    "    return val if val is not None else default_val\n",
    "\n",
    "def cast_tuple(el):\n",
    "    return el if isinstance(el, tuple) else (el,)\n",
    "\n",
    "# tensor related helper functions\n",
    "\n",
    "def top1(t):\n",
    "    # 最后一维的第一大\n",
    "    values, index = t.topk(k=1, dim=-1)\n",
    "    # map(function,iterable)map() 会根据提供的函数对指定序列做映射。\n",
    "    # 第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。\n",
    "    # squeeze去掉dim维，这一维的维度必须为1，相当于降维，去掉维度为1的没用的维度\n",
    "    values, index = map(lambda x: x.squeeze(dim=-1), (values, index))\n",
    "    return values, index\n",
    "\n",
    "def cumsum_exclusive(t, dim=-1):\n",
    "    num_dims = len(t.shape)\n",
    "    num_pad_dims = - dim - 1\n",
    "    pre_padding = (0, 0) * num_pad_dims\n",
    "    pre_slice   = (slice(None),) * num_pad_dims\n",
    "    padded_t = F.pad(t, (*pre_padding, 1, 0)).cumsum(dim=dim)\n",
    "    return padded_t[(..., slice(None, -1), *pre_slice)]\n",
    "\n",
    "# pytorch one hot throws an error if there are out of bound indices.\n",
    "# tensorflow, in contrast, does not throw an error\n",
    "def safe_one_hot(indexes, max_length):\n",
    "    max_index = indexes.max() + 1\n",
    "    return F.one_hot(indexes, max(max_index + 1, max_length))[..., :max_length]\n",
    "\n",
    "def init_(t):\n",
    "    dim = t.shape[-1]\n",
    "    std = 1 / math.sqrt(dim)\n",
    "    return t.uniform_(-std, std)\n",
    "\n",
    "# activations\n",
    "\n",
    "class GELU_(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "GELU = nn.GELU if hasattr(nn, 'GELU') else GELU_\n",
    "\n",
    "# expert class\n",
    "\n",
    "class Experts(nn.Module):\n",
    "    def __init__(self,\n",
    "        dim,\n",
    "        num_experts = 16,\n",
    "        hidden_dim = None,\n",
    "        activation = GELU):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dim = default(hidden_dim, dim * 4)\n",
    "        num_experts = cast_tuple(num_experts)\n",
    "\n",
    "        w1 = torch.zeros(*num_experts, dim, hidden_dim)\n",
    "        w2 = torch.zeros(*num_experts, hidden_dim, dim)\n",
    "\n",
    "        w1 = init_(w1)\n",
    "        w2 = init_(w2)\n",
    "\n",
    "        self.w1 = nn.Parameter(w1)\n",
    "        self.w2 = nn.Parameter(w2)\n",
    "        self.act = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = torch.einsum('...nd,...dh->...nh', x, self.w1)\n",
    "        hidden = self.act(hidden)\n",
    "        out    = torch.einsum('...nh,...hd->...nd', hidden, self.w2)\n",
    "        return out\n",
    "\n",
    "# the below code is almost all transcribed from the official tensorflow version, from which the papers are written\n",
    "# https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/research/moe.py\n",
    "\n",
    "# gating network\n",
    "\n",
    "class Top2Gating(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_gates,\n",
    "        eps = 1e-9,\n",
    "        outer_expert_dims = tuple(),\n",
    "        second_policy_train = 'random',\n",
    "        second_policy_eval = 'random',\n",
    "        second_threshold_train = 0.2,\n",
    "        second_threshold_eval = 0.2,\n",
    "        capacity_factor_train = 1.25,\n",
    "        capacity_factor_eval = 2.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.num_gates = num_gates\n",
    "        # w_gating维度是 outer_expert_dims * dim * num_gates\n",
    "        # 输出是门数，所以最后一维是num_gates\n",
    "        # dim是特征维数，作为中间维度与输入相乘\n",
    "        # outer_experts_dims是啥？\n",
    "        self.w_gating = nn.Parameter(torch.randn(*outer_expert_dims, dim, num_gates))\n",
    "\n",
    "        self.second_policy_train = second_policy_train\n",
    "        self.second_policy_eval = second_policy_eval\n",
    "        self.second_threshold_train = second_threshold_train\n",
    "        self.second_threshold_eval = second_threshold_eval\n",
    "        self.capacity_factor_train = capacity_factor_train\n",
    "        self.capacity_factor_eval = capacity_factor_eval\n",
    "\n",
    "    def forward(self, x, importance = None):\n",
    "        *_, b, group_size, dim = x.shape\n",
    "        num_gates = self.num_gates\n",
    "\n",
    "        # 这应该是module自带参数，train（）的时候为True，eval（）的时候为负\n",
    "        if self.training:\n",
    "            policy = self.second_policy_train\n",
    "            threshold = self.second_threshold_train\n",
    "            capacity_factor = self.capacity_factor_train\n",
    "        else:\n",
    "            policy = self.second_policy_eval\n",
    "            threshold = self.second_threshold_eval\n",
    "            capacity_factor = self.capacity_factor_eval\n",
    "\n",
    "        raw_gates = torch.einsum('...bnd,...de->...bne', x, self.w_gating)\n",
    "        # 最后一维是gate，所以按照最后一维softmax\n",
    "        raw_gates = raw_gates.softmax(dim=-1)\n",
    "\n",
    "        # FIND TOP 2 EXPERTS PER POSITON\n",
    "        # Find the top expert for each position. shape=[batch, group]\n",
    "\n",
    "        gate_1, index_1 = top1(raw_gates)\n",
    "        mask_1 = F.one_hot(index_1, num_gates).float()\n",
    "        density_1_proxy = raw_gates\n",
    "        \n",
    "        # 默认不用L_importance\n",
    "        if importance is not None:\n",
    "            equals_one_mask = (importance == 1.).float()\n",
    "            mask_1 *= equals_one_mask[..., None]\n",
    "            gate_1 *= equals_one_mask\n",
    "            density_1_proxy *= equals_one_mask[..., None]\n",
    "            del equals_one_mask\n",
    "\n",
    "        # mask_1是top1下标的one-hot编码，1-mask_1也就意味着top1对应的位置*0，其他的位置*1\n",
    "        # 变成0了就是最小的了，再一次top1就可以提取出top2了    \n",
    "        gates_without_top_1 = raw_gates * (1. - mask_1)\n",
    "\n",
    "        gate_2, index_2 = top1(gates_without_top_1)\n",
    "        mask_2 = F.one_hot(index_2, num_gates).float()\n",
    "\n",
    "        if importance is not None:\n",
    "            greater_zero_mask = (importance > 0.).float()\n",
    "            mask_2 *= greater_zero_mask[..., None]\n",
    "            del greater_zero_mask\n",
    "\n",
    "        # normalize top2 gate scores\n",
    "        #只保留最大的2个，这里相当于对最大的两个又进行一次softmax\n",
    "        denom = gate_1 + gate_2 + self.eps\n",
    "        gate_1 /= denom\n",
    "        gate_2 /= denom\n",
    "\n",
    "        # BALANCING LOSSES\n",
    "        # shape = [batch, experts]\n",
    "        # We want to equalize the fraction of the batch assigned to each expert\n",
    "        density_1 = mask_1.mean(dim=-2)\n",
    "        # Something continuous that is correlated with what we want to equalize.\n",
    "        # 倒数第二维的维是outer_experts_dim\n",
    "        # 没看懂怎么算的\n",
    "        density_1_proxy = density_1_proxy.mean(dim=-2)\n",
    "        loss = (density_1_proxy * density_1).mean() * float(num_gates ** 2)\n",
    "\n",
    "        # Depending on the policy in the hparams, we may drop out some of the\n",
    "        # second-place experts.\n",
    "        # 对第二expert进行类似dropout的操作，可能删去低于阈值的，可能随机扔一些，可能都不要，可能都要\n",
    "        if policy == \"all\":\n",
    "            pass\n",
    "        elif policy == \"none\":\n",
    "            mask_2 = torch.zeros_like(mask_2)\n",
    "        elif policy == \"threshold\":\n",
    "            mask_2 *= (gate_2 > threshold).float()\n",
    "        elif policy == \"random\":\n",
    "            # uniform_在均匀分布中随机采样，左闭右开\n",
    "            probs = torch.zeros_like(gate_2).uniform_(0., 1.) #[inputs[0], outer_expert_dim]\n",
    "            # 是mask_2*=，不是=，unsqueeze加一维\n",
    "            mask_2 *= (probs < (gate_2 / max(threshold, self.eps))).float().unsqueeze(-1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown policy {policy}\")\n",
    "\n",
    "        # Each sequence sends (at most?) expert_capacity positions to each expert.\n",
    "        # Static expert_capacity dimension is needed for expert batch sizes\n",
    "        expert_capacity = min(group_size, int((group_size * capacity_factor) / num_gates))\n",
    "        expert_capacity = max(expert_capacity, MIN_EXPERT_CAPACITY)\n",
    "        expert_capacity_f = float(expert_capacity)\n",
    "\n",
    "        # COMPUTE ASSIGNMENT TO EXPERTS\n",
    "        # [batch, group, experts]\n",
    "        # This is the position within the expert's mini-batch for this sequence\n",
    "        position_in_expert_1 = cumsum_exclusive(mask_1, dim=-2) * mask_1\n",
    "        # Remove the elements that don't fit. [batch, group, experts]\n",
    "        mask_1 *= (position_in_expert_1 < expert_capacity_f).float()\n",
    "        # [batch, experts]\n",
    "        # How many examples in this sequence go to this expert\n",
    "        mask_1_count = mask_1.sum(dim=-2, keepdim=True)\n",
    "        # [batch, group] - mostly ones, but zeros where something didn't fit\n",
    "        mask_1_flat = mask_1.sum(dim=-1)\n",
    "        # [batch, group]\n",
    "        position_in_expert_1 = position_in_expert_1.sum(dim=-1)\n",
    "        # Weight assigned to first expert.  [batch, group]\n",
    "        gate_1 *= mask_1_flat\n",
    "\n",
    "        position_in_expert_2 = cumsum_exclusive(mask_2, dim=-2) + mask_1_count\n",
    "        position_in_expert_2 *= mask_2\n",
    "        mask_2 *= (position_in_expert_2 < expert_capacity_f).float()\n",
    "        mask_2_flat = mask_2.sum(dim=-1)\n",
    "\n",
    "        position_in_expert_2 = position_in_expert_2.sum(dim=-1)\n",
    "        gate_2 *= mask_2_flat\n",
    "        \n",
    "        # [batch, group, experts, expert_capacity]\n",
    "        combine_tensor = (\n",
    "            gate_1[..., None, None]\n",
    "            * mask_1_flat[..., None, None]\n",
    "            * F.one_hot(index_1, num_gates)[..., None]\n",
    "            * safe_one_hot(position_in_expert_1.long(), expert_capacity)[..., None, :] +\n",
    "            gate_2[..., None, None]\n",
    "            * mask_2_flat[..., None, None]\n",
    "            * F.one_hot(index_2, num_gates)[..., None]\n",
    "            * safe_one_hot(position_in_expert_2.long(), expert_capacity)[..., None, :]\n",
    "        )\n",
    "\n",
    "        dispatch_tensor = combine_tensor.bool().to(combine_tensor)\n",
    "        return dispatch_tensor, combine_tensor, loss\n",
    "\n",
    "# plain mixture of experts\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self,\n",
    "        dim,\n",
    "        num_experts = 16,\n",
    "        hidden_dim = None,\n",
    "        activation = nn.ReLU,\n",
    "        second_policy_train = 'random',\n",
    "        second_policy_eval = 'random',\n",
    "        second_threshold_train = 0.2,\n",
    "        second_threshold_eval = 0.2,\n",
    "        capacity_factor_train = 1.25,\n",
    "        capacity_factor_eval = 2.,\n",
    "        loss_coef = 1e-2,\n",
    "        experts = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "        gating_kwargs = {'second_policy_train': second_policy_train, 'second_policy_eval': second_policy_eval, 'second_threshold_train': second_threshold_train, 'second_threshold_eval': second_threshold_eval, 'capacity_factor_train': capacity_factor_train, 'capacity_factor_eval': capacity_factor_eval}\n",
    "        # 初始化gate，传入门的数量，和超参，没有传入outer_expert_dims\n",
    "        self.gate = Top2Gating(dim, num_gates = num_experts, **gating_kwargs)\n",
    "        self.experts = default(experts, lambda: Experts(dim, num_experts = num_experts, hidden_dim = hidden_dim, activation = activation))\n",
    "        self.loss_coef = loss_coef\n",
    "\n",
    "    def forward(self, inputs, **kwargs):\n",
    "        b, n, d, e = *inputs.shape, self.num_experts\n",
    "        dispatch_tensor, combine_tensor, loss = self.gate(inputs)\n",
    "        expert_inputs = torch.einsum('bnd,bnec->ebcd', inputs, dispatch_tensor)\n",
    "\n",
    "        # Now feed the expert inputs through the experts.\n",
    "        orig_shape = expert_inputs.shape\n",
    "        expert_inputs = expert_inputs.reshape(e, -1, d)\n",
    "        expert_outputs = self.experts(expert_inputs)\n",
    "        expert_outputs = expert_outputs.reshape(*orig_shape)\n",
    "\n",
    "        output = torch.einsum('ebcd,bnec->bnd', expert_outputs, combine_tensor)\n",
    "        return output, loss * self.loss_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609988e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from mixture_of_experts import MoE\n",
    "\n",
    "moe = MoE(\n",
    "    dim = 512,\n",
    "    num_experts = 16,               # increase the experts (# parameters) of your model without increasing computation\n",
    "    hidden_dim = 512 * 4,           # size of hidden dimension in each expert, defaults to 4 * dimension\n",
    "    activation = nn.LeakyReLU,      # use your preferred activation, will default to GELU\n",
    "    second_policy_train = 'random', # in top_2 gating, policy for whether to use a second-place expert\n",
    "    second_policy_eval = 'random',  # all (always) | none (never) | threshold (if gate value > the given threshold) | random (if gate value > threshold * random_uniform(0, 1))\n",
    "    second_threshold_train = 0.2,\n",
    "    second_threshold_eval = 0.2,\n",
    "    capacity_factor_train = 1.25,   # experts have fixed capacity per batch. we need some extra capacity in case gating is not perfectly balanced.\n",
    "    capacity_factor_eval = 2.,      # capacity_factor_* should be set to a value >=1\n",
    "    loss_coef = 1e-2                # multiplier on the auxiliary expert balancing auxiliary loss\n",
    ")\n",
    "\n",
    "inputs = torch.randn(4, 1024, 512)\n",
    "out, aux_loss = moe(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3a666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 1.1544, -0.1697, -1.3483,  0.8665, -1.9129],\n",
      "         [ 2.5419,  0.4158,  0.5876,  1.1696,  0.8588],\n",
      "         [-0.2754, -1.1637, -0.7319, -1.6875, -0.9345],\n",
      "         [ 0.0663,  1.8295,  1.0952,  2.0829,  0.0970]],\n",
      "\n",
      "        [[-1.9983,  1.3038, -1.6020, -0.1983, -0.1377],\n",
      "         [-0.8009, -0.8584,  0.4908, -1.7664,  1.3419],\n",
      "         [-1.6858, -0.4301, -0.0996, -0.5580,  0.3219],\n",
      "         [ 0.1491, -0.5547,  0.4204, -0.0390, -1.5064]],\n",
      "\n",
      "        [[ 0.0232,  0.6683,  0.1763, -0.4046,  0.4990],\n",
      "         [-1.4328,  2.4181, -0.1386, -0.0922, -0.1296],\n",
      "         [ 0.0056,  0.1546,  0.3910,  0.7146,  1.0534],\n",
      "         [-1.4351, -1.7781, -2.5079,  1.3089, -0.6859]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "outer_expert_dims=tuple([3])\n",
    "dim=4\n",
    "num_gates=5\n",
    "w_gating = nn.Parameter(torch.randn(*outer_expert_dims, dim, num_gates))\n",
    "print(w_gating)\n",
    "# 将一个不可训练的类型Tensor转换成可以训练的类型parameter并将这个parameter绑定到这个module里面\n",
    "# (net.parameter()中就有这个绑定的parameter，所以在参数优化的时候可以进行优化的)\n",
    "# 所以经过类型转换变成了模型的一部分，成为了模型中根据训练可以改动的参数了\n",
    "# 使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f1dcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs= tensor([[ 1.1591,  0.0032, -2.7902,  2.0255],\n",
      "        [-0.5143, -0.8529, -0.2640,  0.0589],\n",
      "        [ 0.4107,  2.9308,  0.0175,  0.6375]])\n",
      "raw_gates= tensor([[[ 2.2488,  6.7571,  2.6995,  9.9354,  0.5894],\n",
      "         [ 2.6871,  1.5851, -0.7260,  1.2426, -4.1048],\n",
      "         [-2.9000, -3.2506, -5.9669,  0.1880, -3.7503]],\n",
      "\n",
      "        [[-2.6850,  0.1476,  0.4500, -0.8750,  0.5039],\n",
      "         [ 2.1646,  0.1425,  0.4563,  1.7535, -1.2474],\n",
      "         [ 1.1241, -2.5515, -0.2233,  0.1751, -0.4646]],\n",
      "\n",
      "        [[ 7.9613,  2.2948,  1.8538,  5.0821,  1.7767],\n",
      "         [-3.1022, -2.3415,  1.0467, -5.2929,  2.9218],\n",
      "         [-5.1043,  6.2305, -1.9258,  0.4105, -0.5937]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "raw_gates= tensor([[[4.4005e-04, 3.9944e-02, 6.9059e-04, 9.5884e-01, 8.3720e-05],\n",
      "         [6.2416e-01, 2.0736e-01, 2.0559e-02, 1.4722e-01, 7.0084e-04],\n",
      "         [4.1474e-02, 2.9210e-02, 1.9313e-03, 9.0966e-01, 1.7722e-02]],\n",
      "\n",
      "        [[1.4015e-02, 2.3812e-01, 3.2219e-01, 8.5643e-02, 3.4003e-01],\n",
      "         [4.9765e-01, 6.5875e-02, 9.0162e-02, 3.2990e-01, 1.6410e-02],\n",
      "         [5.3288e-01, 1.3500e-02, 1.3850e-01, 2.0630e-01, 1.0881e-01]],\n",
      "\n",
      "        [[9.3992e-01, 3.2521e-03, 2.0923e-03, 5.2803e-02, 1.9370e-03],\n",
      "         [2.0840e-03, 4.4595e-03, 1.3206e-01, 2.3308e-04, 8.6117e-01],\n",
      "         [1.1898e-05, 9.9567e-01, 2.8567e-04, 2.9546e-03, 1.0824e-03]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs=torch.randn(3,4)\n",
    "print(\"inputs=\",inputs)\n",
    "# *_, b, group_size, dim = inputs.shape\n",
    "# print(\"_,b,group_size,dim=\",_,b,group_size,dim)\n",
    "raw_gates = torch.einsum('ad,bde->abe', inputs, w_gating)\n",
    "print(\"raw_gates=\",raw_gates)\n",
    "raw_gates = raw_gates.softmax(dim=-1)\n",
    "print(\"raw_gates=\",raw_gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8d4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_1,index_1=top1(raw_gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8885ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9588, 0.6242, 0.9097],\n",
      "        [0.3400, 0.4977, 0.5329],\n",
      "        [0.9399, 0.8612, 0.9957]], grad_fn=<SqueezeBackward1>) tensor([[3, 0, 3],\n",
      "        [4, 0, 0],\n",
      "        [0, 4, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(gate_1,index_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da25aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9588],\n",
      "         [0.6242],\n",
      "         [0.9097]],\n",
      "\n",
      "        [[0.3400],\n",
      "         [0.4977],\n",
      "         [0.5329]],\n",
      "\n",
      "        [[0.9399],\n",
      "         [0.8612],\n",
      "         [0.9957]]], grad_fn=<TopkBackward0>) tensor([[[3],\n",
      "         [0],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [4],\n",
      "         [1]]])\n",
      "tensor([[0.9588, 0.6242, 0.9097],\n",
      "        [0.3400, 0.4977, 0.5329],\n",
      "        [0.9399, 0.8612, 0.9957]], grad_fn=<SqueezeBackward1>) tensor([[3, 0, 3],\n",
      "        [4, 0, 0],\n",
      "        [0, 4, 1]])\n"
     ]
    }
   ],
   "source": [
    "values, index = raw_gates.topk(k=1, dim=-1)\n",
    "print(values, index)\n",
    "values, index = map(lambda x: x.squeeze(dim=-1), (values, index))\n",
    "print(values, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d30b2326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "tensor([[[4.4005e-04, 3.9944e-02, 6.9059e-04, 0.0000e+00, 8.3720e-05],\n",
      "         [0.0000e+00, 2.0736e-01, 2.0559e-02, 1.4722e-01, 7.0084e-04],\n",
      "         [4.1474e-02, 2.9210e-02, 1.9313e-03, 0.0000e+00, 1.7722e-02]],\n",
      "\n",
      "        [[1.4015e-02, 2.3812e-01, 3.2219e-01, 8.5643e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 6.5875e-02, 9.0162e-02, 3.2990e-01, 1.6410e-02],\n",
      "         [0.0000e+00, 1.3500e-02, 1.3850e-01, 2.0630e-01, 1.0881e-01]],\n",
      "\n",
      "        [[0.0000e+00, 3.2521e-03, 2.0923e-03, 5.2803e-02, 1.9370e-03],\n",
      "         [2.0840e-03, 4.4595e-03, 1.3206e-01, 2.3308e-04, 0.0000e+00],\n",
      "         [1.1898e-05, 0.0000e+00, 2.8567e-04, 2.9546e-03, 1.0824e-03]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask_1 = F.one_hot(index_1, num_gates).float()\n",
    "density_1_proxy = raw_gates\n",
    "print(mask_1)\n",
    "gates_without_top_1 = raw_gates * (1. - mask_1)\n",
    "print(gates_without_top_1)\n",
    "gate_2, index_2 = top1(gates_without_top_1)\n",
    "mask_2 = F.one_hot(index_2, num_gates).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ed41f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density_1= tensor([[0.3333, 0.0000, 0.0000, 0.6667, 0.0000],\n",
      "        [0.6667, 0.0000, 0.0000, 0.0000, 0.3333],\n",
      "        [0.3333, 0.3333, 0.0000, 0.0000, 0.3333]])\n",
      "density_1_proxy= tensor([[0.2220, 0.0922, 0.0077, 0.6719, 0.0062],\n",
      "        [0.3482, 0.1058, 0.1836, 0.2073, 0.1551],\n",
      "        [0.3140, 0.3345, 0.0448, 0.0187, 0.2881]], grad_fn=<MeanBackward1>)\n",
      "loss= tensor(1.8632, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "density_1 = mask_1.mean(dim=-2)\n",
    "print(\"density_1=\", density_1)\n",
    "# Something continuous that is correlated with what we want to equalize.\n",
    "density_1_proxy = density_1_proxy.mean(dim=-2)\n",
    "print(\"density_1_proxy=\", density_1_proxy)\n",
    "loss = (density_1_proxy * density_1).mean() * float(num_gates ** 2)\n",
    "print(\"loss=\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2af62",
   "metadata": {},
   "source": [
    "1. outer_experts_dim 是什么？为什么初始化的时候不传入，初始为 tuple()\n",
    "2. loss到底是什么原理\n",
    "3. expert_capacity是干什么的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f00ed717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs= tensor([[0.2740, 0.5237, 0.1820],\n",
      "        [0.2794, 0.5914, 0.1781],\n",
      "        [0.9341, 0.2405, 0.6881]])\n",
      "drop= tensor([[[0.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[0.],\n",
      "         [1.],\n",
      "         [0.]]])\n",
      "gate_2= tensor([[0.0399, 0.2074, 0.0415],\n",
      "        [0.3222, 0.3299, 0.2063],\n",
      "        [0.0528, 0.1321, 0.0030]], grad_fn=<SqueezeBackward1>)\n",
      "mask_2 tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "probs = torch.zeros_like(gate_2).uniform_(0., 1.)\n",
    "print(\"probs=\",probs)\n",
    "print(\"drop=\",(probs < (gate_2 / max(0.2, 1e-9))).float().unsqueeze(-1))\n",
    "mask_2 *= (probs < (gate_2 / max(0.2, 1e-9))).float().unsqueeze(-1)\n",
    "print(\"gate_2=\", gate_2)\n",
    "print(\"mask_2\",mask_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74463338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
